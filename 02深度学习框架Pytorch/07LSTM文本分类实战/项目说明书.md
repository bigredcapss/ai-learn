# LSTM文本分类实战项目说明书

## 项目概述

本项目是一个基于PyTorch框架的中文文本分类实战项目，主要实现了多种深度学习模型对中文新闻文本进行分类。项目支持多种经典文本分类模型，包括TextCNN、TextRNN等，并提供了完整的训练、验证和测试流程。

### 项目特点
- **多模型支持**：支持TextCNN、TextRNN等多种文本分类模型
- **中文文本处理**：专门针对中文文本进行优化
- **预训练词向量**：支持搜狗新闻和腾讯词向量
- **完整训练流程**：包含数据预处理、模型训练、验证和测试
- **可视化监控**：集成TensorBoard进行训练过程可视化

## 数据集信息

### THUCNews数据集
- **数据来源**：清华大学新闻数据集
- **类别数量**：10个新闻类别
- **类别列表**：
  - finance（财经）
  - realty（房产）
  - stocks（股票）
  - education（教育）
  - science（科技）
  - society（社会）
  - politics（政治）
  - sports（体育）
  - game（游戏）
  - entertainment（娱乐）

### 数据分布
- **训练集**：train.txt（约9.5MB）
- **验证集**：dev.txt（约538KB，10001条数据）
- **测试集**：test.txt（约539KB，10001条数据）

## 技术架构

### 核心模块

#### 1. 模型模块（models/）
- **TextCNN.py**：基于卷积神经网络的文本分类模型
- **TextRNN.py**：基于循环神经网络的文本分类模型

#### 2. 工具模块
- **utils.py**：通用工具函数，包含数据预处理、词表构建等
- **utils_fasttext.py**：FastText模型专用工具函数
- **train_eval.py**：训练和评估核心逻辑

#### 3. 主程序
- **run.py**：项目入口，负责参数解析和流程控制

### 模型架构详解

#### TextCNN模型
```python
# 核心特点
- 使用多个不同尺寸的卷积核（2, 3, 4）
- 卷积核数量：256个
- 支持预训练词向量
- 使用最大池化和dropout防止过拟合
```

#### TextRNN模型
```python
# 核心特点
- 双向LSTM结构
- LSTM层数：2层
- 隐藏层大小：128
- 支持预训练词向量
- 使用dropout防止过拟合
```

## 环境配置

### 依赖包
```bash
torch>=1.0.0
numpy
scikit-learn
tqdm
tensorboardX
```

### 预训练词向量
- **搜狗新闻词向量**：embedding_SougouNews.npz（6.0MB）
- **腾讯词向量**：embedding_Tencent.npz（4.0MB）

## 使用方法

### 1. 基本训练命令

#### 训练TextRNN模型
```bash
python run.py --model TextRNN --embedding pre_trained --word False
```

#### 训练TextCNN模型
```bash
python run.py --model TextCNN --embedding pre_trained --word False
```

### 2. 参数说明

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| --model | str | 必需 | 选择模型：TextCNN, TextRNN |
| --embedding | str | pre_trained | 词向量类型：random或pre_trained |
| --word | bool | False | True为词级别，False为字符级别 |

### 3. 训练配置参数

#### 通用配置
- **批次大小**：128
- **学习率**：1e-3
- **训练轮数**：10-20轮
- **序列长度**：32（短填长切）
- **词向量维度**：300
- **Dropout率**：0.5

#### 模型特定配置

**TextCNN配置**
- 卷积核尺寸：(2, 3, 4)
- 卷积核数量：256
- 训练轮数：20

**TextRNN配置**
- LSTM隐藏层大小：128
- LSTM层数：2
- 训练轮数：10

## 训练流程

### 1. 数据预处理
1. 构建词表（vocab.pkl）
2. 文本转换为数字序列
3. 序列填充/截断到固定长度
4. 构建数据迭代器

### 2. 模型训练
1. 初始化模型和优化器
2. 训练循环：
   - 前向传播
   - 计算损失
   - 反向传播
   - 参数更新
3. 定期验证和模型保存
4. 早停机制（1000个batch无改善）

### 3. 模型评估
1. 加载最佳模型
2. 在测试集上评估
3. 输出准确率、精确率、召回率、F1分数
4. 生成混淆矩阵

## 性能监控

### TensorBoard可视化
- **训练损失**：实时监控训练损失变化
- **验证损失**：监控验证集损失
- **训练准确率**：监控训练准确率
- **验证准确率**：监控验证准确率

### 日志输出
- 每100个batch输出一次训练状态
- 包含训练损失、准确率、验证损失、准确率
- 显示训练时间

## 文件结构

```
07LSTM文本分类实战/
├── models/                    # 模型定义
│   ├── TextCNN.py            # CNN文本分类模型
│   └── TextRNN.py            # RNN文本分类模型
├── THUCNews/                 # 数据集
│   ├── data/                 # 数据文件
│   │   ├── train.txt         # 训练集
│   │   ├── dev.txt           # 验证集
│   │   ├── test.txt          # 测试集
│   │   ├── class.txt         # 类别列表
│   │   ├── vocab.pkl         # 词表
│   │   ├── embedding_SougouNews.npz  # 搜狗词向量
│   │   └── embedding_Tencent.npz     # 腾讯词向量
│   └── saved_dict/           # 保存的模型
├── run.py                    # 主程序入口
├── train_eval.py             # 训练评估逻辑
├── utils.py                  # 通用工具函数
└── utils_fasttext.py         # FastText工具函数
```

## 扩展功能

### 支持的模型类型
- TextCNN：卷积神经网络
- TextRNN：循环神经网络
- FastText：快速文本分类
- TextRCNN：RNN+CNN混合模型
- TextRNN_Att：带注意力机制的RNN
- DPCNN：深度金字塔CNN
- Transformer：Transformer模型

### 自定义扩展
1. 在models/目录下添加新的模型文件
2. 实现Config类和Model类
3. 在run.py中添加模型选择选项

## 注意事项

1. **内存要求**：预训练词向量较大，确保有足够内存
2. **GPU加速**：支持CUDA加速，建议使用GPU训练
3. **数据格式**：训练数据格式为"文本\t标签"
4. **早停机制**：避免过拟合，自动停止训练
5. **模型保存**：最佳模型自动保存到saved_dict目录

## 常见问题

### Q1: 如何修改训练参数？
A: 在对应模型的Config类中修改参数，如学习率、批次大小等。

### Q2: 如何添加新的数据集？
A: 准备数据文件（train.txt, dev.txt, test.txt, class.txt），修改Config类中的路径配置。

### Q3: 如何自定义模型？
A: 参考现有模型结构，在models/目录下创建新的模型文件。

### Q4: 训练过程中如何监控？
A: 使用TensorBoard查看训练日志：`tensorboard --logdir=THUCNews/log/`

## 项目优势

1. **代码结构清晰**：模块化设计，易于理解和扩展
2. **功能完整**：包含完整的训练、验证、测试流程
3. **中文优化**：专门针对中文文本处理进行优化
4. **多模型支持**：支持多种经典文本分类模型
5. **可视化监控**：集成TensorBoard进行训练监控
6. **预训练支持**：支持多种预训练词向量
